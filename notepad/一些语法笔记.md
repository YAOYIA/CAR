# 智能指针
理解智能指针的循环引用：首先要明确其设计的目标--通过引用计数(shared_ptr)或者独占所有权(unique_ptr,weak_ptr)，自动管理内存，避免内存泄漏。而循环引用是shared_ptr
(基于引用计数)特有的风险，本质是两个或者多个对象通过shared_ptr互相指向，导致他们的引用的计数永远无法减至0，最终内存无法释放。
首先要明确的一点是只有share_ptr存在循环引用问题
unique_ptr:独占所有权，同一时间只有一个unique_ptr指向对象，无法拷贝，不存在多个指针互相指向的情景，因此不会存在循环引用
weak_ptr:弱引用，不参与引用计数的计算，仅作为“观察者”指向shared_ptr管理的对象，本身无法直接访问对象（需要先通过lock()转为shared_ptr），因此不会发生循环引用。
shared_ptr:共享所有权，多个shared_ptr可以指向同一个对象，内部共同维护一个引用计数。

循环引用的根源，正是 shared_ptr 的 “共享所有权” 和 “引用计数” 机制 —— 当对象间通过 shared_ptr 形成闭环时，它们的引用计数会互相 “卡住”，永远无法归零。

```
#include <iostream>
#include <memory>
#include <mutex>


class Node
{
private:
    /* data */
public:
    int value;
    std::shared_ptr<Node> prev;
    // 将 prev 改为 weak_ptr 的核心是打破了 “双向强引用” 的闭环：
    // next 保留为 shared_ptr，保证 “后继节点” 的生命周期能被当前节点正常持有；
    // prev 改为 weak_ptr，避免对 “前驱节点” 形成强引用，从而让前驱节点的引用计数能正常减至 0 并析构；
    // 简单来说：weak_ptr 既保留了 “指向另一个节点” 的能力，又不会因为这个指向而增加引用计数，从而打破了循环引用的死锁，让对象的引用计数能正常归零并析构。
    // std::weak_ptr<Node> prev;
    std::shared_ptr<Node> next;
    Node(int val):value(val)
    {
        std::cout<<"Node 构造"<<std::endl;
    }
    ~Node()
    {
        std::cout<<"Node 析构"<<std::endl;
    }
};

/*
为什么会这样？我们一步步拆解引用计数的变化过程：
创建节点时：
node1（shared_ptr）指向 Node(1)，Node(1) 的引用计数 = 1；
node2（shared_ptr）指向 Node(2)，Node(2) 的引用计数 = 1。
互相指向时：
node1->next = node2：Node(2) 新增一个 shared_ptr 指向它，引用计数 +1 → 2；
node2->prev = node1：Node(1) 新增一个 shared_ptr 指向它，引用计数 +1 → 2。
函数结束时：
node1 和 node2 是 testCycle 函数的局部变量，出作用域后会被销毁：
node1 销毁 → Node(1) 的引用计数 -1 → 1（此时仍有 node2->prev 指向它）；
node2 销毁 → Node(2) 的引用计数 -1 → 1（此时仍有 node1->next 指向它）。
最终状态：
Node(1) 和 Node(2) 的引用计数都停留在 1，永远无法减至 0；
系统无法判断这两个对象是否还在被使用，因此不会释放它们的内存 —— 这就是循环引用导致的内存泄漏。
*/
void testCycle()
{
    //1.创建两个shared_ptr,分别管理node1和node2
    std::shared_ptr<Node> node1 = std::make_shared<Node>(1);
    std::shared_ptr<Node> node2 = std::make_shared<Node>(2);

    //2.让两个节点互相指向，形成闭环
    node1->next = node2;
    node2->prev = node1;

}

int main()
{
    testCycle();
    std::cout<<"test end"<<std::endl;
    return 0;
}
```

# 为什么使用虚拟头、尾节点？核心目的是简化链表操作的边界判断，避免空指针的问题
没有虚拟节点时的痛点：
插入第一个真实节点时，需要判断 “链表是否为空”（头指针是否为 nullptr）；
删除最后一个真实节点时，需要判断 “是否只剩一个节点”（避免尾指针为空）；
边界操作逻辑复杂，容易出现空指针崩溃。

有虚拟节点后的优势：
插入节点：无论链表是否为空，真实节点都只需插入 dummyHead_->next 和 dummyHead 之间（头部插入），或任意两个节点之间，无需判断边界；
示例：插入节点 node 到头部：node->prev = dummyHead_ → node->next = dummyHead_->next → dummyHead_->next->prev = node → dummyHead_->next = node。
删除节点：无论删除哪个真实节点（包括最后一个），都只需修改该节点前后节点的指针，无需判断 “是否是头 / 尾节点”；
示例：删除节点 node：node->prev->next = node->next → node->next->prev = node->prev。
判空逻辑简化：只需判断 dummyHead_->next == dummyTail_ 即可知道链表是否为空（无真实节点）。



# unique_lock
互斥锁封装类，定义在mutex的结构体中，是管理互斥锁std::mutex,std::recursive_mutex的灵活工具，作用是自动管理锁的加锁与解锁，避免手动操作导致的死锁或者遗漏解锁问题。
核心特性：
1.独占所有权：一个std::unique_lock实列独占一个互斥锁的所有权（同一时间只会有一个unique_lock能关联到该互斥锁），但是支持临时解锁和重新加锁。
2.RALL机制：构造的时候，自动解锁，析构的时候，自动解锁
构造方式	说明
unique_lock<mutex> lock(mtx);	构造时立即对 mtx 加锁（默认策略，等价于 mtx.lock()）
unique_lock<mutex> lock(mtx, defer_lock);	延迟加锁：构造时不锁定，后续需手动调用 lock() 或 try_lock()
unique_lock<mutex> lock(mtx, try_to_lock);	尝试加锁：构造时调用 mtx.try_lock()，成功则持有锁，失败则不持有（无阻塞）
unique_lock<mutex> lock(mtx, adopt_lock);	接管已加锁的互斥锁：要求调用方已手动加锁，unique_lock 仅接管所有权，析构时解锁
unique_lock<mutex> lock(mtx, chrono::seconds(1));	限时加锁：在指定时间内尝试加锁，超时则放弃

函数	功能
lock()	手动加锁（仅当构造时用 defer_lock 或已解锁时有效）
unlock()	手动解锁（临时释放锁，后续可重新加锁）
try_lock()	尝试加锁（无阻塞），成功返回 true，失败返回 false
owns_lock()	判断当前是否持有锁
release()	释放对互斥锁的所有权（返回指向互斥锁的指针），析构时不再解锁
mutex()	返回关联的互斥锁指针

# std::lock_guard
核心逻辑：构造时自动加锁，析构时自动解锁
std::lock_guard是轻量级的锁封装，仅构造加锁、析构解锁，无手动解锁、重新加锁的能力


#加锁的原理
通过操作系统、编译器提供的同步原语，为共享资源划定 互斥访问区域，确保同一时间只有一个线程进入该区域操作共享资源，其底层依赖硬件和操作系统内核的调度机制。核心逻辑为：
1.原子操作：锁的底层支撑
锁的实现依赖原子指令（如test-and-set、compare-and-swap，简称 CAS），这类指令能保证 “读取 - 修改 - 写入” 的操作序列不可被中断（CPU 层面独占执行），是实现互斥的基础。
举例：test-and-test指令会先读取内存中锁的状态，再原子性地将其设为”已锁定“，并返回原始的状态。
作用：避免多线程同时修改锁的状态
2.阻塞、唤醒机制：避免忙等
当线程尝试获取已被占用的锁时，操作系统会将该线程从 “运行态” 切换为 “阻塞态”（挂起），并将其放入锁的等待队列；当持有锁的线程释放锁时，操作系统会从等待队列中唤醒一个（或多个）线程，使其重新竞争锁。
对比：简单的 “自旋锁” 仅依赖原子操作（线程循环检测锁状态，不挂起），适合短时间持锁场景；而std::mutex（互斥锁）结合了原子操作 + 阻塞 / 唤醒，适合长时间持锁场景，避免 CPU 空耗。

锁时如何保证
1.互斥性：同一个时间仅有一个线程持有锁
加锁阶段：线程调用lock()时，底层原子指令会检查锁的状态：
若锁未被占用：原子性标记为 “已占用”，线程进入临界区（操作共享资源）；
若锁已被占用：线程被阻塞（或自旋等待），直到锁被释放。
解锁阶段：线程调用unlock()时，原子性将锁标记为 “未占用”，并通知操作系统唤醒等待队列中的线程，重新竞争锁。
效果：临界区（加锁后的代码块）成为 “互斥区”，任何时刻只有一个线程能执行其中的代码，从根本上避免多线程同时修改共享资源。
2. 可见性：保证线程间数据同步
锁不仅保证互斥，还隐含 “内存屏障（Memory Barrier）” 的语义：
加锁时：刷新 CPU 缓存，使当前线程能读取到其他线程已写入的最新数据；
解锁时：将当前线程的修改刷回主存，使其他线程后续能看到该修改。
作用：避免因 CPU 缓存、指令重排导致的 “线程间数据不一致”（比如线程 A 修改了共享变量但未刷回主存，线程 B 读取到旧值）。



|维度|	互斥锁（如 C++ std::mutex）|	自旋锁|
|------|------|-----|
|等待策略|	线程获取锁失败时，主动放弃 CPU，进入阻塞（休眠）状态，让出 CPU 给其他线程；直到锁被释放，线程被唤醒重新竞争锁。	|线程获取锁失败时，不放弃 CPU，通过循环（自旋）不断尝试获取锁，直到成功。|
|CPU 资源消耗|	阻塞 / 唤醒有上下文切换开销，但等待期间不占用 CPU 资源。|	自旋期间持续占用 CPU 核心，若等待时间长，会导致 CPU 空转、利用率飙升。|
|切换开销|	存在上下文切换（用户态→内核态）和线程调度开销（唤醒、重新调度）。|	无上下文切换开销（全程用户态），仅消耗 CPU 周期。|
|适用场景|	临界区执行时间 较长（如 I/O 操作、复杂计算、循环次数多的场景），或线程等待锁的概率 / 时间高。|	临界区执行时间 极短（如仅修改一个变量），且锁竞争频率低、等待时间短。|
|死锁风险|	若线程持有锁时异常退出且未释放，可能导致死锁；需配合lock_guard/unique_lock等 RAII 机制避免。|	除常规死锁场景（如交叉锁），若自旋时间过长，可能因优先级反转等问题加剧死锁风险。|
|实现层面|	依赖操作系统内核调度（内核态锁），C++ 标准库std::mutex是典型实现。|	多为用户态实现（如基于原子操作），无需内核介入，响应速度更快。|


# std::condition_varible
本质是线程间的 唤醒通知器，，wait函数则是 等待通知的接口，他让当前线程暂时放弃CPU，进入阻塞的状态，直到其他的线程通知notify_one发送唤醒信号，才会尝试重新恢复运行。
std::condition_varible是引入的同步原语，属于 condition_varible 头文件，用于线程之间的条件等待。让一个、多个线程等待某个条件成立，直到其他的线程显示通知它。
核心特性：
1.必须与std:mutex配合使用
2.支持 等待-通知 模型，解决【忙等】轮询的性能问题
3.可能存在 虚假唤醒（无通知却被唤醒），因此等待条件必须是循环判断

核心接口
1.等待接口（线程阻塞）
|接口	|说明|
|-----|----|
|void wait(std::unique_lock<std::mutex>& lock)	|阻塞线程，直到被通知；解锁 mutex，被唤醒后重新加锁|
|template<class Predicate> void wait(std::unique_lock<std::mutex>& lock, Predicate pred)	|带条件的等待，等价于 while(!pred()) { wait(lock); }，避免虚假唤醒|
|std::cv_status wait_for(lock, duration)	|限时等待，超时返回 cv_status::timeout|
|std::cv_status wait_until(lock, time_point)|	等待到指定时间点，超时返回 cv_status::timeout|

2.通知接口 唤醒线程
|接口|	说明|
|-----|-----|
|void notify_one()	|唤醒一个等待该条件变量的线程（若有）|
|void notify_all()	|唤醒所有等待该条件变量的线程（若有）|



# 进程 线程 协程
一、进程process
进程是操作系统进行资源分配何调度的基本单位，是程序的一次执行过程。
特点:
1.独立性：每个进程拥有独立的地址空间、数据栈和代码段
2.资源隔离：进程间资源相互隔离，一个进程崩溃不会影响到其他的进程。
3.通信复杂：进程间的通信需要通过特定的机制：
管道、消息队列、共享内存、套接字、信号
4.开销大：创建、销毁、切换的成本高
5.稳定性高：进程间隔离性好，安全性高。
二、线程thread
定义：
线程是进程内的一个执行单元，是CPU调度的基本单位
特点：
1.共享资源：同一个进程内的线程共享内存空间和系统资源
2.轻量级：创建、销毁、切换成本比进程低
3.通信简单：线程间可以直接读写共享数据（需要同步机制）
4.并发执行：多线程可实现真正的并行（多核CPU）
5.同步问题：需要处理竟态条件、死锁等问题。
三、协程 coroutine
定义：
协程是用户态的轻量级线程，由程序控制调度，而非操作系统内核。
特点：
1.轻量级：一个线程可以运行上万个协程
2.用户态调度：切换在用户态完成，开销极小
3.协作式调度：需要主动让出执行权
4.异步非阻塞：适合I/O密集型任务
5.简化异步编程：用同步方式写异步代码




|特性|	进程|	线程|	协程|
|----|-----|-----|----|
|调度单位|	操作系统|	操作系统|	程序自身|
|切换开销|	大（内核态切换）|	中等（内核态切换）	极小（用户态切换）
|内存占用|	大（独立地址空间）|	小（共享进程内存）	极小（KB级别）|
|隔离性	|完全隔离	共享内存	|共享内存|
|通信方式|	IPC（管道、共享内存等）|	共享变量+同步机制	消息传递、共享变量|
|适用场景|	CPU密集型、需要隔离	CPU密集型、多核并行	|I/O密集型、高并发|
|创建数量|	几十到几百	|几百到几千|	几万到几十万|
|实现语言|	所有支持多进程的语言|	所有支持多线程的语言|	Python、Go、Kotlin等|


使用进程的场景：
1.需要完全隔离的执行环境
2.CPU密集型任务，且需要利用多核CPU
3.程序稳定性要求高，一个模块崩溃不影响其他

使用线程的场景
1.需要共享内存和数据的并行任务
2.有大量I/O操作，但需要简单共享状态
3.需要利用多核CPU的并行计算

使用协程的场景
1.高并发IO密集型应用
2.需要大量并发连接
3.希望用同步方式写异步代码


内存管理总结
1.虚拟内存为每个进程提供独立的地址空间。
2.分段将内存按照功能划分（代码、数据、堆、栈）。
3.分页实现虚拟到物理的映射，支持交换和共享。
4.权限控制保护内存安全。
5.多级缓存提高访问效率。




虚拟地址空间分为：内核空间、用户空间。操作系统运行在内核空间，用户程序运行在用户空间。
内核空间中存在进程的控制信息。





# 链表遍历宏 
## LIST_FOR_EACH_ENTRY 宏
Linux内核中最核心的双向链表遍历宏，属于内核侵入式双向链表，作用是遍历链表的同时，直接获取包含链表节点的外层容器结构体指针，避免手动计算结构体偏移。
```
struct list_head {
    struct list_head *next, *prev;
};
```

```
struct my_struct {
    int data;
    struct list_head list;
};
```

这个宏用于遍历链表，从头节点开始，直到回到头节点为止，需要三个参数：
pos：当前遍历到的结构体指针.
head：链表的头节点
member:在结构体中链表节点成员的名字
```
#define LIST_FOR_EACH_ENTRY(pos, head, member)                          \
    for (pos = list_first_entry(head, typeof(*pos), member);            \
         &pos->member != (head);                                        \
         pos = list_next_entry(pos, member))
```

## LIST_FOR_EACH_ENTRY_SAFE 宏
也是遍历节点，但是允许在遍历的时候删除节点
```
#define LIST_FOR_EACH_ENTRY_SAFE(pos, n, head, member)                  \
    for (pos = list_first_entry(head, typeof(*pos), member),            \
         n = list_next_entry(pos, member);                              \
         &pos->member != (head);                                        \
         pos = n, n = list_next_entry(n, member))
```
pos: 同上，指向当前结构体的指针。
n: 另一个同类型的指针，用于临时保存下一个节点，防止在删除当前节点后无法找到下一个节点。
head: 链表的头节点。
member: 链表节点成员的名字。


## TLS 局部线程存储
